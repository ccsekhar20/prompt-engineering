{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1783485e-d7cb-4808-a7e8-d54a5354fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from PyPDF2 import PdfReader\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Kor!\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n",
    "\n",
    "# LangChain Models\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Standard Helpers\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# For token counting\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223f6281-f736-4730-9ac2-2393361e0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a11a0b5-69a3-44bd-afdb-5b063263b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a45239-3f95-49c4-a64d-8c149b71f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the PDF file\n",
    "reader = PdfReader('/Users/ccsekhar/Downloads/archive/data/data/ACCOUNTANT/10554236.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15594168-7378-4b4d-b2c1-f62f438b632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each page in the PDF and extract text\n",
    "raw_text = ''\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef1b2ab8-d344-449b-b1fa-fa14cee3c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the raw text into chunks using the text splitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03297a8f-3b74-4d6e-a914-4fd84151972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI embeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6066e4-3f0f-45d1-90ad-a65093f8ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS index for similarity search from the text chunks\n",
    "docsearch = FAISS.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a37ab1-1a8a-4685-a6eb-297358fe1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = len(texts[0])  # Dimension of the vectors\n",
    "nlist = 32  # Number of cells (clusters) in the IVF index\n",
    "quantizer = faiss.IndexFlatL2(d)  # The quantizer index\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20496f0-9e6c-4364-a6ca-be413d462167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store all embeddings\n",
    "all_embeddings = []\n",
    "for chunk in texts:\n",
    "    embedding = embeddings.embed_documents(chunk)\n",
    "    all_embeddings.append(embedding)  # Collect all embeddings for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3aa569-e291-4dae-b4d4-3f262361dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of embeddings to a NumPy array\n",
    "all_embeddings = np.array(all_embeddings, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b44260-65ae-4f4c-9bd1-bf9dc6080be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the index using all_embeddings\n",
    "index.train(all_embeddings)\n",
    "# Add all_embeddings to the index\n",
    "index.add(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f82f201a-dc91-4ed6-ae45-4235c609bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the question-answering chain\n",
    "chain = load_qa_chain(OpenAI(), chain_type = \"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192bd33-966e-4217-8932-9bef8686d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the question answering chain (to summarize)\n",
    "query = \"Can you summarize the resume in the form of key value pairs? (make sure to include ALL THE INFORMATION and in a listed order)\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents = docs, question = query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
